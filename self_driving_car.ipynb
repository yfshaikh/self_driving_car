{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db35778",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3482172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import tensorboard\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31a40a",
   "metadata": {},
   "source": [
    "# 2. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02d5c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CarRacing-v2\" # a racing game from the gymnasium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d81919c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an instance of the CarRacing-v2 environment\n",
    "env = gym.make(environment_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "106e4e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the environment to its initial state. This is necessary before starting a new episode\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f150ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-881.0750000001095\n",
      "Episode:2 Score:-888.6960912053229\n",
      "Episode:3 Score:-388.96666666666493\n",
      "Episode:4 Score:-855.4929292930328\n",
      "Episode:5 Score:-889.8939393940508\n"
     ]
    }
   ],
   "source": [
    "# The agent selects random actions from the action space, simulates one episode of the game, and prints the total score after the episode ends.\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        # Renders the environment to visualize what is happening during each step of the simulation. It displays the current state of the environment.\n",
    "        env.render()\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a58f3",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4160aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f7b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_path = os.path.join('Training', 'Logs')\n",
    "# having some bugs with tensorboard so not saving logs for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64ca5a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# set up model\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "870c962b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 167  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 12   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010575086 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.00148     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.311       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 0.883       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009005702 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00597832 |\n",
      "|    clip_fraction        | 0.0759     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.21      |\n",
      "|    explained_variance   | 0.0757     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.173      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 0.624      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010530841 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011767486 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0749      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011603745 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011803158 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016165525 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015277375 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.923       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010798957 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 422        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01964857 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.94      |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0394     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    std                  | 0.899      |\n",
      "|    value_loss           | 0.313      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015110149 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0723      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 0.446       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016737867 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020808382 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018732674 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 609        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02050377 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.74      |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0229     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.84       |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 645        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02308095 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.153      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    std                  | 0.825      |\n",
      "|    value_loss           | 0.508      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 681        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02609694 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.66      |\n",
      "|    explained_variance   | 0.887      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0961     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    std                  | 0.816      |\n",
      "|    value_loss           | 0.374      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027671225 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 0.407       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x281268990>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc28af",
   "metadata": {},
   "source": [
    "# 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1ba161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models', 'PPO_Driving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "312fb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70125d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# delete and load model from saved path to confirm it works\n",
    "del model\n",
    "model = PPO.load(ppo_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9fbc4",
   "metadata": {},
   "source": [
    "# 5. Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dedc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c51a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e96fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
